{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716bb603",
   "metadata": {},
   "source": [
    "## Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5175ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StopWordsRemover, VectorAssembler, StringIndexer, RegexTokenizer\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, DecisionTreeClassifier, LogisticRegression, GBTClassifier, MultilayerPerceptronClassifier, LinearSVC, FMClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.sql.functions import length, col, count_distinct\n",
    "import gc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647beeb4",
   "metadata": {},
   "source": [
    "## Initiating a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb50b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-BJS1Q67:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sms_spam_detection</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f76ec87dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('sms_spam_detection').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf75b0",
   "metadata": {},
   "source": [
    "## Loading the SMS spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e61a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('smsspamcollection/SMSSpamCollection',inferSchema=True,sep='\\t')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18118ee",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec73fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da5d63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc8cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|   ham|Go until jurong p...|\n",
      "|   ham|Ok lar... Joking ...|\n",
      "|  spam|Free entry in 2 a...|\n",
      "|   ham|U dun say so earl...|\n",
      "|   ham|Nah I don't think...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('_c0','target').withColumnRenamed('_c1','text')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321b4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+\n",
      "|target|                text|length|\n",
      "+------+--------------------+------+\n",
      "|   ham|Go until jurong p...|   111|\n",
      "|   ham|Ok lar... Joking ...|    29|\n",
      "|  spam|Free entry in 2 a...|   155|\n",
      "|   ham|U dun say so earl...|    49|\n",
      "|   ham|Nah I don't think...|    61|\n",
      "+------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('length',length(col('text')))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b384531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|target|count|\n",
      "+------+-----+\n",
      "|   ham| 4827|\n",
      "|  spam|  747|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('target').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4b612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|target|      avg(length)|\n",
      "+------+-----------------+\n",
      "|   ham|71.45431945307645|\n",
      "|  spam|138.6706827309237|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('target').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4de8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol='text',outputCol='tokens',pattern='\\\\W')\n",
    "stopwords_remover = StopWordsRemover(inputCol='tokens',outputCol='filtered_tokens')\n",
    "count_vect = CountVectorizer(inputCol='filtered_tokens',outputCol='vectorized_tokens')\n",
    "idf = IDF(inputCol='vectorized_tokens',outputCol='tf_idf')\n",
    "assembler = VectorAssembler(inputCols=['length','tf_idf'],outputCol='features')\n",
    "indexer = StringIndexer(inputCol='target',outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ba0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "976a35e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_eeda5428d848"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[indexer,tokenizer,stopwords_remover,count_vect,idf,assembler])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1739a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_f35dd0773d98"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep_pipe = pipeline.fit(df)\n",
    "data_prep_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f35a08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|target|                text|length|label|              tokens|     filtered_tokens|   vectorized_tokens|              tf_idf|            features|\n",
      "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(8623,[11,16,37,6...|(8623,[11,16,37,6...|(8624,[0,12,17,38...|\n",
      "|   ham|Ok lar... Joking ...|    29|  0.0|[ok, lar, joking,...|[ok, lar, joking,...|(8623,[0,9,247,37...|(8623,[0,9,247,37...|(8624,[0,1,10,248...|\n",
      "|  spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(8623,[2,10,23,24...|(8623,[2,10,23,24...|(8624,[0,3,11,24,...|\n",
      "|   ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(8623,[0,56,81,85...|(8623,[0,56,81,85...|(8624,[0,1,57,82,...|\n",
      "|   ham|Nah I don't think...|    61|  0.0|[nah, i, don, t, ...|[nah, think, goes...|(8623,[52,137,372...|(8623,[52,137,372...|(8624,[0,53,138,3...|\n",
      "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df = data_prep_pipe.transform(df)\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6896b9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target',\n",
       " 'text',\n",
       " 'length',\n",
       " 'label',\n",
       " 'tokens',\n",
       " 'filtered_tokens',\n",
       " 'vectorized_tokens',\n",
       " 'tf_idf',\n",
       " 'features']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68924c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(8624,[0,12,17,38...|\n",
      "|  0.0|(8624,[0,1,10,248...|\n",
      "|  1.0|(8624,[0,3,11,24,...|\n",
      "|  0.0|(8624,[0,1,57,82,...|\n",
      "|  0.0|(8624,[0,53,138,3...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df = transformed_df.select('label','features')\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea91d33",
   "metadata": {},
   "source": [
    "## Splitting transformed data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7966aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = transformed_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb00b110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3882, 1692)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa5f9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|    (8624,[0],[7.0])|\n",
      "|  0.0|    (8624,[0],[7.0])|\n",
      "|  0.0|   (8624,[0],[27.0])|\n",
      "|  0.0|(8624,[0,1],[8.0,...|\n",
      "|  0.0|(8624,[0,1],[12.0...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b76b0aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|    (8624,[0],[3.0])|\n",
      "|  0.0|   (8624,[0],[10.0])|\n",
      "|  0.0|   (8624,[0],[24.0])|\n",
      "|  0.0|   (8624,[0],[27.0])|\n",
      "|  0.0|(8624,[0,1,2,4,19...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "264c9355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveBayesModel: uid=NaiveBayes_dcaeaadd5e39, modelType=multinomial, numClasses=2, numFeatures=8624"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = NaiveBayes().fit(train_df)\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67511e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|    (8624,[0],[3.0])|[-1.6471524253324...|[0.89472073661644...|       0.0|\n",
      "|  0.0|   (8624,[0],[10.0])|[-5.1453959403931...|[0.94522751789885...|       0.0|\n",
      "|  0.0|   (8624,[0],[24.0])|[-12.141882970514...|[0.98614179778159...|       0.0|\n",
      "|  0.0|   (8624,[0],[27.0])|[-13.641130191254...|[0.98973297891914...|       0.0|\n",
      "|  0.0|(8624,[0,1,2,4,19...|[-611.13050409227...|[1.0,3.9870607150...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results = nb_model.transform(test_df)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b193ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "f1_eval = MulticlassClassificationEvaluator(metricName='f1')\n",
    "precision_eval = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "recall_eval = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "roc_auc_eval = BinaryClassificationEvaluator(metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04683123",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = acc_eval.evaluate(test_results)\n",
    "f1 = f1_eval.evaluate(test_results)\n",
    "precision = precision_eval.evaluate(test_results)\n",
    "recall = recall_eval.evaluate(test_results)\n",
    "roc_auc = roc_auc_eval.evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23200342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes: 0.9598108747044918\n",
      "Precision of Naive Bayes: 0.9658926063018967\n",
      "Recall of Naive Bayes: 0.9598108747044917\n",
      "ROC AUC Score of Naive Bayes: 0.1712152062018643\n",
      "F1 Score of Naive Bayes: 0.9615055324909287\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Naive Bayes:\",acc)\n",
    "print(\"Precision of Naive Bayes:\",precision)\n",
    "print(\"Recall of Naive Bayes:\",recall)\n",
    "print(\"ROC AUC Score of Naive Bayes:\",roc_auc)\n",
    "print(\"F1 Score of Naive Bayes:\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450efa43",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a0e8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db182941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model):\n",
    "    clf = model.fit(train_df)\n",
    "    test_results = clf.transform(test_df)\n",
    "    acc_eval = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "    f1_eval = MulticlassClassificationEvaluator(metricName='f1')\n",
    "    precision_eval = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "    recall_eval = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "    roc_auc_eval = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "    acc = acc_eval.evaluate(test_results)\n",
    "    f1 = f1_eval.evaluate(test_results)\n",
    "    precision = precision_eval.evaluate(test_results)\n",
    "    recall = recall_eval.evaluate(test_results)\n",
    "    roc_auc = roc_auc_eval.evaluate(test_results)\n",
    "    model_name = str(model).split('(')[0]\n",
    "    print(f\"Accuracy of {model_name}:\",acc)\n",
    "    print(f\"Precision of {model_name}:\",precision)\n",
    "    print(f\"Recall of {model_name}:\",recall)\n",
    "    print(f\"ROC AUC Score of {model_name}:\",roc_auc)\n",
    "    print(f\"F1 Score of {model_name}:\",f1)\n",
    "    model_names.append(model)\n",
    "    accuracy_scores.append(acc)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    del acc, f1, precision, recall, roc_auc, acc_eval, precision_eval, recall_eval, f1_eval, roc_auc_eval\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc7a13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression_72f09ac2241f: 0.9810874704491725\n",
      "Precision of LogisticRegression_72f09ac2241f: 0.9809270524852111\n",
      "Recall of LogisticRegression_72f09ac2241f: 0.9810874704491725\n",
      "ROC AUC Score of LogisticRegression_72f09ac2241f: 0.9814095835493843\n",
      "F1 Score of LogisticRegression_72f09ac2241f: 0.9806874782247222\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f020fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes_ef524dd0597d: 0.9598108747044918\n",
      "Precision of NaiveBayes_ef524dd0597d: 0.9658926063018967\n",
      "Recall of NaiveBayes_ef524dd0597d: 0.9598108747044917\n",
      "ROC AUC Score of NaiveBayes_ef524dd0597d: 0.1712152062018643\n",
      "F1 Score of NaiveBayes_ef524dd0597d: 0.9615055324909287\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(NaiveBayes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39c27e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LinearSVC_998131734ff5: 0.9816784869976359\n",
      "Precision of LinearSVC_998131734ff5: 0.9814915869906106\n",
      "Recall of LinearSVC_998131734ff5: 0.9816784869976359\n",
      "ROC AUC Score of LinearSVC_998131734ff5: 0.9900914344972407\n",
      "F1 Score of LinearSVC_998131734ff5: 0.9815478123979356\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f7c6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier_0597e20c012b: 0.9373522458628841\n",
      "Precision of DecisionTreeClassifier_0597e20c012b: 0.9348901266289947\n",
      "Recall of DecisionTreeClassifier_0597e20c012b: 0.9373522458628841\n",
      "ROC AUC Score of DecisionTreeClassifier_0597e20c012b: 0.5570706815221378\n",
      "F1 Score of DecisionTreeClassifier_0597e20c012b: 0.9315693223367296\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94732780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier_78ee4567735d: 0.8764775413711584\n",
      "Precision of RandomForestClassifier_78ee4567735d: 0.8917805608456266\n",
      "Recall of RandomForestClassifier_78ee4567735d: 0.8764775413711584\n",
      "ROC AUC Score of RandomForestClassifier_78ee4567735d: 0.9450918771261999\n",
      "F1 Score of RandomForestClassifier_78ee4567735d: 0.821614847168587\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba70416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GBTClassifier_d2f310e9795a: 0.9515366430260047\n",
      "Precision of GBTClassifier_d2f310e9795a: 0.949930045557557\n",
      "Recall of GBTClassifier_d2f310e9795a: 0.9515366430260047\n",
      "ROC AUC Score of GBTClassifier_d2f310e9795a: 0.960438455604315\n",
      "F1 Score of GBTClassifier_d2f310e9795a: 0.9487344497466098\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(GBTClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8b91570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of FMClassifier_afe3053b6f5c: 0.966903073286052\n",
      "Precision of FMClassifier_afe3053b6f5c: 0.9661061897287664\n",
      "Recall of FMClassifier_afe3053b6f5c: 0.9669030732860521\n",
      "ROC AUC Score of FMClassifier_afe3053b6f5c: 0.8940472727732621\n",
      "F1 Score of FMClassifier_afe3053b6f5c: 0.9662030868932642\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(FMClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fd8a6",
   "metadata": {},
   "source": [
    "## Baseline Models Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "421ad34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC_998131734ff5</td>\n",
       "      <td>0.981678</td>\n",
       "      <td>0.981492</td>\n",
       "      <td>0.981678</td>\n",
       "      <td>0.981548</td>\n",
       "      <td>0.990091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression_72f09ac2241f</td>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.980927</td>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.980687</td>\n",
       "      <td>0.981410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FMClassifier_afe3053b6f5c</td>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.966106</td>\n",
       "      <td>0.966903</td>\n",
       "      <td>0.966203</td>\n",
       "      <td>0.894047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes_ef524dd0597d</td>\n",
       "      <td>0.959811</td>\n",
       "      <td>0.965893</td>\n",
       "      <td>0.959811</td>\n",
       "      <td>0.961506</td>\n",
       "      <td>0.171215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBTClassifier_d2f310e9795a</td>\n",
       "      <td>0.951537</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.951537</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.960438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier_0597e20c012b</td>\n",
       "      <td>0.937352</td>\n",
       "      <td>0.934890</td>\n",
       "      <td>0.937352</td>\n",
       "      <td>0.931569</td>\n",
       "      <td>0.557071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_78ee4567735d</td>\n",
       "      <td>0.876478</td>\n",
       "      <td>0.891781</td>\n",
       "      <td>0.876478</td>\n",
       "      <td>0.821615</td>\n",
       "      <td>0.945092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  Accuracy  Precision    Recall  \\\n",
       "0               LinearSVC_998131734ff5  0.981678   0.981492  0.981678   \n",
       "1      LogisticRegression_72f09ac2241f  0.981087   0.980927  0.981087   \n",
       "2            FMClassifier_afe3053b6f5c  0.966903   0.966106  0.966903   \n",
       "3              NaiveBayes_ef524dd0597d  0.959811   0.965893  0.959811   \n",
       "4           GBTClassifier_d2f310e9795a  0.951537   0.949930  0.951537   \n",
       "5  DecisionTreeClassifier_0597e20c012b  0.937352   0.934890  0.937352   \n",
       "6  RandomForestClassifier_78ee4567735d  0.876478   0.891781  0.876478   \n",
       "\n",
       "         F1   ROC AUC  \n",
       "0  0.981548  0.990091  \n",
       "1  0.980687  0.981410  \n",
       "2  0.966203  0.894047  \n",
       "3  0.961506  0.171215  \n",
       "4  0.948734  0.960438  \n",
       "5  0.931569  0.557071  \n",
       "6  0.821615  0.945092  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perfs = pd.DataFrame({'Model': model_names, \n",
    "                            'Accuracy': accuracy_scores, \n",
    "                            'Precision': precision_scores,\n",
    "                            'Recall': recall_scores,\n",
    "                            'F1': f1_scores,\n",
    "                            'ROC AUC': roc_auc_scores}).sort_values(by='F1',ascending=False).reset_index(drop=True)\n",
    "model_perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "416444e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC_998131734ff5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model_perfs.iloc[0]['Model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7604b3",
   "metadata": {},
   "source": [
    "The Linear SVC model has emerged as the best performing spam detection classifier achieving an incredible accuracy of more than 98% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69a820fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_07d605f8a16b"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_pipeline = Pipeline(stages=[tokenizer,stopwords_remover,count_vect,idf,assembler,best_model])\n",
    "best_model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba3df2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.LinearSVC"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b351ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.Pipeline"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(best_model_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c3e192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy or sad , one thing about past is- \"Its no more\" GOOD MORNING :-):-).'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(rand()).first()['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d29f3d",
   "metadata": {},
   "source": [
    "## Saving the best model pipeline for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "95551fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pipeline.save('sms_spam_detector/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
